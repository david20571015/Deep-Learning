{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_ds, test_ds), info = tfds.load('cifar10',\n",
    "                                      split=['train', 'test'],\n",
    "                                      shuffle_files=True,\n",
    "                                      as_supervised=True,\n",
    "                                      with_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.divide(tf.cast(image, tf.float32), 255.), label\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.cache()\n",
    "train_ds = train_ds.shuffle(info.splits['train'].num_examples)\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = test_ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "test_ds = test_ds.cache()\n",
    "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2_REG = 0\n",
    "KERNEL_SIZE = 3\n",
    "STRIDE_SIZE = 1\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=info.features['image'].shape),  # type: ignore\n",
    "    tf.keras.layers.Conv2D(filters=64,\n",
    "                           kernel_size=KERNEL_SIZE,\n",
    "                           strides=STRIDE_SIZE,\n",
    "                           padding='same',\n",
    "                           activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(L2_REG)),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Conv2D(filters=128,\n",
    "                           kernel_size=KERNEL_SIZE,\n",
    "                           strides=STRIDE_SIZE,\n",
    "                           padding='same',\n",
    "                           activation='relu',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(L2_REG)),\n",
    "    tf.keras.layers.MaxPool2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64,\n",
    "                          activation='relu',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(L2_REG)),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(10,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(L2_REG)),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "logdir = os.path.join(\n",
    "    'logs',\n",
    "    'cifar10',\n",
    "    f'filter_{KERNEL_SIZE}_stride_{STRIDE_SIZE}_l2_{L2_REG}',\n",
    ")\n",
    "os.makedirs(logdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(logdir, 'model.json'), 'w', encoding='utf-8') as f:\n",
    "    print(model.to_json(), file=f)\n",
    "\n",
    "\n",
    "def log_summary(string):\n",
    "    print(string)\n",
    "    with open(os.path.join(logdir, 'summary.txt'), 'a', encoding='utf-8') as f:\n",
    "        print(string, file=f)\n",
    "\n",
    "\n",
    "model.summary(print_fn=print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    validation_data=test_ds,\n",
    "    callbacks=[tensorboard_callback],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for data, label in test_ds.unbatch():\n",
    "    preds = model(data[tf.newaxis, ...])[0]\n",
    "    pred = tf.argmax(preds).numpy()\n",
    "    label = label.numpy()\n",
    "\n",
    "    if pred == label:\n",
    "        print(f'pred: {pred}, label: {label}')\n",
    "        plt.imshow(data.numpy(), cmap='gray')\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, label in test_ds.unbatch():\n",
    "    preds = model(data[tf.newaxis, ...])[0]\n",
    "    pred = tf.argmax(preds).numpy()\n",
    "    label = label.numpy()\n",
    "\n",
    "    if pred != label:\n",
    "        print(f'pred: {pred}, label: {label}')\n",
    "        plt.imshow(data.numpy(), cmap='gray')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data, sample_label = next(iter(train_ds.unbatch().take(1)))\n",
    "sample_data = sample_data[tf.newaxis, ...]\n",
    "plt.imshow(sample_data.numpy().squeeze(), cmap='gray')\n",
    "print(sample_label.numpy())\n",
    "\n",
    "features = {}\n",
    "for layer in model.layers:\n",
    "    sample_data = layer(sample_data)\n",
    "    if 'conv2d' in layer.name:\n",
    "        features.update({layer.name: sample_data})\n",
    "\n",
    "for name, feature in features.items():\n",
    "    print(name)\n",
    "    print(feature.shape)\n",
    "\n",
    "    figure = plt.figure(figsize=(15, 15))\n",
    "    for i in range(feature.shape[-1]):\n",
    "        ax = figure.add_subplot(16, 8, i + 1)\n",
    "        ax.imshow(feature[0, :, :, i].numpy(), cmap='gray')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dl-hw2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9340feaedc0ba7dc470917c52803b4ba17714809ed33171f54617c22fd28f3ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
